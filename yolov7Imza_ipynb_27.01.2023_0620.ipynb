{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vc9JistkmBtu1RhZ7nVRL20_zBZmFDFa",
      "authorship_tag": "ABX9TyN/i/ugW1f9UlTaSLSoFH16"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ojmV0iyCipp"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "!wget \"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\""
      ],
      "metadata": {
        "id": "dLwOle0CE_rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "!python train.py --batch 16 --cfg cfg/training/yolov7.yaml --epochs 200 --data /content/drive/MyDrive/imzaTestTrainData/labels/ --weights \"yolov7.pt\" --device 0"
      ],
      "metadata": {
        "id": "j3DrAV0SGvX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5600a9-554d-4838-9b21-bd6154d4ff36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 587, in <module>\n",
            "    opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n",
            "  File \"/content/yolov7/utils/general.py\", line 151, in check_file\n",
            "    assert len(files), f'File Not Found: {file}'  # assert file was found\n",
            "AssertionError: File Not Found: /content/drive/MyDrive/imzaTestTrainData/labels/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQQJVZbRo1s8",
        "outputId": "7fec90d8-c4f1-469a-b4ef-a72a730e5f36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights best_imza.pt --conf 0.4 --source inference/images/imza1.png"
      ],
      "metadata": {
        "id": "aOMPQfFyxNmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576c08d0-4d7d-4d5c-ad68-2c2820eb075e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.4, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/images/imza1.png', update=False, view_img=False, weights=['best_imza.pt'])\n",
            "YOLOR üöÄ v0.1-121-g2fdc7f1 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15109.875MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Model Summary: 306 layers, 36490696 parameters, 6194944 gradients\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "1 imza, Done. (18.6ms) Inference, (19.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp22/imza1.png\n",
            "Done. (0.579s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/MyDrive/yolov7\")\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Lx75j69epJki",
        "outputId": "a94ccb12-f766-485a-9fd8-c25ad08afc14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-335193f4fea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/yolov7\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/yolov7'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/yolov7\")\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Jo5wX3YUxmgP",
        "outputId": "3828b0bc-803b-4fd7-cc33-1c8c5d045971"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/yolov7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!# Download YOLOv7 code\n",
        "#!git clone https://github.com/WongKinYiu/yolov7\n",
        "#%cd yolov7\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "from models.yolo import Model\n",
        "from utils.general import check_requirements, set_logging\n",
        "from utils.google_utils import attempt_download\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "dependencies = ['torch', 'yaml']\n",
        "check_requirements(Path(\".\").parent / 'requirements.txt', exclude=('pycocotools', 'thop'))\n",
        "set_logging()\n",
        "\n"
      ],
      "metadata": {
        "id": "cUjsHe2Apk14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d043914-c30a-4f12-d1c5-901348d3b0f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m jedi>=0.10 not found and is required by YOLOR, attempting auto-update...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.6/1.6 MB 29.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10) (0.8.3)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/drive/MyDrive/yolov7/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "s1SBSZ76qrdL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom(path_or_model, autoshape=True):\n",
        "    \"\"\"custom mode\n",
        "\n",
        "    Arguments (3 options):\n",
        "        path_or_model (str): 'path/to/model.pt'\n",
        "        path_or_model (dict): torch.load('path/to/model.pt')\n",
        "        path_or_model (nn.Module): torch.load('path/to/model.pt')['model']\n",
        "\n",
        "    Returns:\n",
        "        pytorch model\n",
        "    \"\"\"\n",
        "    model = torch.load(path_or_model, map_location=torch.device('cpu')) if isinstance(path_or_model, str) else path_or_model  # load checkpoint\n",
        "    if isinstance(model, dict):\n",
        "        model = model['ema' if model.get('ema') else 'model']  # load model\n",
        "\n",
        "    hub_model = Model(model.yaml).to(next(model.parameters()).device)  # create\n",
        "    hub_model.load_state_dict(model.float().state_dict())  # load state_dict\n",
        "    hub_model.names = model.names  # class names\n",
        "    if autoshape:\n",
        "        hub_model = hub_model.autoshape()  # for file/URI/PIL/cv2/np inputs and NMS\n",
        "    device = select_device('0' if torch.cuda.is_available() else 'cpu')  # default to GPU if available\n",
        "    return hub_model.to(device)\n",
        "\n",
        "model = custom(path_or_model='best_imza.pt')  # custom example\n",
        "# model = create(name='yolov7', pretrained=True, channels=3, classes=80, autoshape=True)  # pretrained example\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3nT3jQXqGvc",
        "outputId": "fc64c07d-8d2f-4c5c-c364-07b49a5e529f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding autoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Verify inference\n",
        "#import numpy as np\n",
        "#from PIL import Image\n",
        "import pandas as pd \n",
        "\n",
        "#imgs = [np.zeros((640, 480, 3))]\n",
        "\n",
        "results = model(\"inference/images/imza1.png\")  # batched inference\n",
        "\n",
        "df_prediction = results.pandas().xyxy\n",
        "print(df_prediction)\n",
        "\n",
        "[a.split(\"\\t\") for a in df_prediction[0]]"
      ],
      "metadata": {
        "id": "F42hgTMFqnQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb146978-b3db-4b0d-e5bd-7ccbc3b9e28f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   xmin       ymin        xmax        ymax  confidence  class  name\n",
            "0   0.0  54.807426  705.676575  517.873047    0.462402      2  imza]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['xmin'], ['ymin'], ['xmax'], ['ymax'], ['confidence'], ['class'], ['name']]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y29uY_3myNKA"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}